---
title: "CS 422 Section 01"
output: html_notebook
author: Zhongzhu Ding
---

## Homework 3(p3)

### Part 2.3-A-i
a) Perform PCA on the dataset and answer the following questions:
(i) How much cumulative variance is explained by the first two components?

```{r}
rm(list = ls())
setwd("/users/enrique/desktop/IITstudy/CS422 Data mining/hw/hw3")
pulsar <- read.csv("HTRU_2.csv",header = T,sep = ",")
pulsar.pca <- prcomp(pulsar[,1:8],center = TRUE,scale. = TRUE)
summary(pulsar.pca)
```
(i)Answer:the cumulative variance of the first two components are 0.5257 and 0.7699

### Part 2.3-A-ii
(ii) Plot the first two principal components. Use a different color to represent the observations in the two classes. 

```{r}
plot(pulsar.pca,type="line",main="Scree Plot for pulsar")
abline(h=1, col="blue")
```

```{r}
vars <- (pulsar.pca$sdev)^2 
vars
```

```{r}
props <- vars / sum(vars)    
props
```

```{r}
cumulative.props <- cumsum(props)  # aggregated effects
cumulative.props
```

```{r}
# pca$rotation 
top2_pca.data <- pulsar.pca$x[, 1:2]
top2.pca.eigenvector <- pulsar.pca$rotation[, 1:2]
top2.pca.eigenvector

first.pca <- top2.pca.eigenvector[, 1]
second.pca <- top2.pca.eigenvector[, 2]
first.pca[order(first.pca, decreasing=FALSE)]
second.pca[order(second.pca, decreasing=FALSE)]    
dotchart(first.pca[order(first.pca, decreasing=FALSE)] ,main="Loading Plot for PC1", xlab="Variable Loadings",col="red")
dotchart(second.pca[order(second.pca, decreasing=FALSE)] ,main="Loading Plot for PC2", xlab="Variable Loadings",col="blue")
```

```{r}
#PCA loadings plot
biplot(pulsar.pca, scale=0) 
```

### Part 2.3-A-iii

(iii) Describe what you see with respect to the actual label of the HTRU2 dataset.

Anwser:
The candidates in the upper-left area have the bigger mean and standard deviation of the intergrated profile.
The candidates in the upper-right area have the bigger mean and standard deviation of the DM-SNR curve.
The candidates in the lower-left area have the bigger Excess kurtosis of the intergrated profile and DM-SNR curve.
The candidates in the lower-right area have the bigger skewness of the intergrated profile and DM-SNR curve.

### Part 2.3-B-i
(b) We know that the HTRU2 dataset has two classes. We will now use K-means on the HTRU2 dataset.
(i) Perform K-means clustering on the dataset with k = 2. Plot the resulting clusters.
```{r}
library(cluster)
library(factoextra)

k <- kmeans(pulsar[,1:8],centers = 2,nstart = 25)
fviz_cluster(k,data = pulsar[,1:8])
```

### Part 2.3-B-ii
(ii) Provide observations on the shape of the clusters you got in (b)(i) to the plot of the first two principal components in (a)(ii). If the clusters are are similar, why? If they are not, why?

Answer :They are not similar.Although PCA tries to reduce the reconstruction error and tries to get components that can represent the original data, there is no guarantee that these components will help distinguish between different categories.

### Part 2.3-B-iii
(iii) What is the distribution of the observations in each cluster?
```{r}
k
```

 Answer:The distribution of observations in 2 clusters are 2596 and 15302.
 
### Part 2.3-B-iv
(iv) What is the distribution of the classes in the HTRU2 dataset?

```{r}
table(pulsar$class)
```

Answer:The distribution of observations in 2 classes are :16259 in class 0 and 1639 in class 1.

### Part 2.3-B-v
(v) Based on the distribution of the classes in (b)(iii) and (b)(iv), which cluster do you think corresponds to the majority class and which cluster corresponds to the minority class?

Answer:cluster 2 that in size 15302 corresponds to the majority class,cluster 1 that in size 2596 corresponds to the minority class.

### Part 2.3-B-vi
(vi) Letâ€™s focus on the larger cluster. Get all of the observations that belong to this cluster. Then, state what is the distribution of the classes within this large cluster; i.e., how many observations in this large cluster belong to class 1 and how many belong to class 0?

Answer:

```{r}
table(pulsar$class[k$cluster==1])
```

Answer:13693 observations belong to class 0 and 1609 observations belong to class 1.

### Part 2.3-B-vii
(vii) Based on the analysis above, which class (1 or 0) do you think the larger cluster represents?

Answer:the larger cluster represents class 0.

### Part 2.3-B-viii
(viii) How much variance is explained by the clustering?

```{r}
mean.class <- mean(as.numeric(pulsar$class))
sum((k$cluster - mean.class)^2) / sum((as.numeric(pulsar$class) - mean.class)^2)

```

Answer:the variance value is 14.83142

### Part 2.3-B-ix
(ix) What is the average Silhouette width of both the clusters?

```{r}
silh <- cluster::silhouette(k$cluster, dist(pulsar[,1:8]))
mean(silh[, 3])
```

Answer:the average Silhouette width is 0.5947

### Part 2.3-B-x
(x) What is the per cluster Silhouette width? Based on this, which cluster is good?

```{r}
tapply(silh[, 3], silh[, 1], mean)
```

### Part 2.3-C-i
(c) Perform K-means on the result of the PCA you ran in (a). More specifically, perform K-means on the first two principal component score vectors (i.e., pca$x[, 1:2]). Use k = 2.
(i) Plot the clusters and comment on their shape with respect to the plots of a(ii) and b(i).

```{r}
kmeans.pca <- kmeans(pulsar.pca$x[, 1:2], 2)
fviz_cluster(kmeans.pca, data = pulsar.pca$x[, 1:2], geom = "points")
```

Answer:with respect to the plots of a(ii) and b(i),the shape of clusters is more clear and simple.And the area of cluster 1 decreased.Proabably it is getting far from the true value.

### Part 2.3-C-ii
(ii) What is the average Silhouette width of both the clusters?
```{r}
silh.pc <- cluster::silhouette(kmeans.pca$cluster, dist(pulsar.pca$x[, 1:2]))
mean(silh.pc[, 3])
```

Answer: the average Silhouette width is 0.652.

### Part 2.3-C-iii
(iii) What is the per cluster Silhouette width? Based on this, which cluster is good?
```{r}
tapply(silh.pc[, 3], silh.pc[, 1], mean)
```


### Part 2.3-C-iv
(iv) How do the values of c(ii) and c(iii) compare with those of b(ix) and b(x), respectively?

Answer:the values of c(ii) and c(iii) are better because both the average Silhouette width and the per cluster Silhouette width increased.